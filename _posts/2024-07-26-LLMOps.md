---
layout: post
title: LLMOps Specialization
subtitle: Large Language Model Operations
# cover-img: /assets/img/path.jpg
# thumbnail-img: /assets/img/thumb.png
# share-img: /assets/img/path.jpg
tags: [LLMs]
---

## Key Terms

**Tokenizer** - The process of splitting text into smaller chunks or "tokens" and assigning each one a number.

**Encoding** - Converting the text tokens into numeric representations.

**Probability machine** - How LLMs work by predicting the probability of the next token based on the previous ones.

**Fine-tuning** - Further training a pretrained LLM on more specific data to adapt it to a particular task.

**Prompt engineering** - Crafting the input text carefully to get better results from an LLM.

**Retrieval augmentation** - Combining search/retrieval with an LLM to improve results.

**Risk mitigation** - Strategies like prompt engineering and fine-tuning to reduce risks of using LLMs.

**Foundation model** - A large pretrained deep learning model that can be adapted to other tasks.

**Repurposing** - Using a foundation model for a task different than its original purpose.

**Code assistant** - An example application built by fine-tuning a foundation model for coding.
